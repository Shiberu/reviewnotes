= Chapter 6 =

inner product
  positivity (v,v), definiteness (v,v), additivity in first slot, homogeneity in first slot, conjugate symmetry

Euclidean inner product on F^n: sum{ui * conjugate(wi)}

Triangle Inequality (prove by squaring both sides and apply Cauchy), Pythagorean Theorem

Cauchy-Schwarz Inequality (|<u,v>| <= |u||v|, eq holds iff one is scalar multiple of the other) prove by orthogonal decomposition

parallelogram equality: |u+v|^2 + |u-v|^2 = 2(|u|^2 + |v|^2)

orthonormal list of vectors => linearly independent (prove by checking norm)

(e1...) orthonormal basis => v = <v,e1>e1 + ..., |v|^2 = |<v,e1>|^2 + ...

Gram-Schmidt: (v1,...) l.i. list of vectors => exists orthonormal (e1,...) s.t. span equal
    ej = orthonormalize(vj - <vj,e1>e1 - ... - <vj, e{j-1}>e{j-1})

every orthonormal list of vectors can be extended to an orthonormal basis (first extend & then G-S)

T has u.t.m => T has u.t.m. w.r.t. some orthonormal basis

orthogonal complement: U^perp
  [U subspace of V] V = U oplus U^perp
  U = U^perp^perp
  P_U is called the orthogonal projection of V onto U

orthogonal projection: |v - P_U v| <= |v - u| for all u in U, eq holds iff u = P_U v

unitary / orthogonal matrix: matrix over C / R s.t. columns form an orthonormal basis of R^n with the Euclidean inner product
  Q unitary / orthogonal <=> T(x) = Qx isometry <=> QQ* = I <=> Q* unitary / orthogonal <=> rows of Q form an orthonormal basis

adjoint: T in L(V, w), T^* maps from W to V s.t. <Tv, w> = <v, T^*w>.
  (aT)* = conjugate(a)T^*
  null T^* = (range T)^perp
  range T^* = (null T)^perp
  Suppose (e1, .., en) orthonormal basis of V, (f1, ..., fn) orthonormal basis of W, then M(T^*, (f1, ..., fn), (e1, ..., en)) = conjugate_transpose(M(T, (e1, ..., en), (f1, ..., fn)))
  T injective <=> T* surjective

= Chapter 7 =

self-adjoint: operator T in L(V) s.t. T = T^*
  every eigenvalue real
  [V complex, <Tv, v> = 0 for all v in V] => T = 0
    proof technique: <Tu, w> = (<T(u+w), u+w> - <T(u-w), u-w>) / 4 + i(<T(i((u+w)), i(u+w)> - <T(i((u-w)), i(u-w)>) / 4
  [V real, T self-adjoint, <Tv, v> = 0 for all v in V] => T = 0
    proof technique: <Tu, w> = (<T(u+w), u+w> - <T(u-w), u-w>) / 4
  [V complex] T self-adjoint <=> <Tv, v> in R for all v in V
    proof technique: <Tv, v> - conjugate(<Tv, v>) = <(T - T^*)v, v>

<u, v> = 0 iff norm(u) <= norm(u+av) for all a in F

[P in L(V), P^2 = P]
  P orthogonal projection <=> P self-adjoint
  norm(Pv) <= norm(v) for every v in V => P orthogonal projection
  every vector in null P orthogonal to every vector in range P => P orthogonal projection

normal: T operator in L(V), TT^* = T^*T
  T normal <=> norm(Tv) = norm(T^*v) for all v in V
  T normal => [v in V eigenvector of T with eigenvalue lambda <=> eigenvector of T^* with eigenvalue conjugate(lambda)]
  T normal => eigenvectors of T corresponding to distinct eigenvalues are orthogonal
  [T normal, U invariant subspace] =>
    U^perp invariant under T
    U invariant under T^*
    (T|U)^* = (T^*)|U
    T|U normal operator on U
    T|U^perp normal operator on U^perp

Spectral Theorem:
  [V complex / real], V has an orthonormal basis consisting of eigenvectors of T <=> T is normal / self-adjoint
    proof technique:
      if V complex, exists orthonormal basis s.t. M(T) upper triangular, argue actually diagonal
      if V real, prove by induction on dimension of V, pick any eigenvector with norm 1, argue T|_({v}^perp) self-adjoint
        Lemma: [T in L(V) self-adjoint], a, b in R s.t. a^2 < 4b => T^2 + aT + bI invertible
        Lemma: [T in L(V) self-adjoint] => T has an eigenvalue
  Corollary:
    [F = R && T self-adjoint || F = C && T normal], lambda_1 .. lambda_n distinct eigenvalues of T => V = null(T-lambda_1 I) directsum ... directsum null(T-lambda_n I). Furthermore, each vector in each null(T-lambda_j I) is orthogonal to all vectors in the other subspaces of this decomposition

positive operator: (V real && T self-adjoint || V complex) and <Tv, v> >= 0 for all v in V
  T is positive <=>
    T is self-adjoint and all the eigenvalues of T are nonnegative <=>
    T has a positive square root <=>
    T has a self-adjoint square root <=>
    exists S in L(V) s.t. T = S*S
  Has unique positive square root

isometry: norm(Tv) = norm(v) for all v in V
  S is an isometry <=> <Su, Sv> = <u, v> for all u, v in V <=> S*S = I <=> (Se1, ..., Sen) is orthonormal whenever (e1, ..., en) orthonormal in V <=> exists (e1, ..., en) s.t. (Se1, ..., Sen) orthonormal <=> S* isometry
  isometry => normal
  [V complex, S in L(V)]. S isometry <=> exists orthonormal basis of V consisting of eigenvectors of S all of whose corresponding eigenvalues have absolute value 1
  //[V real, S in L(V)]. S isometry <=> exists orthonormal basis of V w.r.t. which S has a block diagonal matrix where each block

polar decomposition: [T in L(V)]. exists isometry S in L(V) s.t. T = S*sqrt(T^*T)
  proof technique: observe that norm(Tv) = norm(sqrt(T^*T)v) for all v. define S1: range(sqrt(T^*T)) -> range(T), S2: range(sqrt(T^*T))^perp -> range(T)^perp. define S: Sv = S1u + S2w where v = u + w

singular value: eigenvalue of sqrt(T^*T)

singular-value decomposition: suppose T in L(V) has singular values s1, ..., sn. Then there exist orthonormal bases (e1, ..., en) and (f1, ..., fn) of V such that Tv = s1<v, e1>f1 + ... + sn<v, en>fn for every v in V


= Chapter 8 =
generalized eigenvector: v generalized eigenvector if (T-lambda I)^j v = 0 for some positive integer j

//if T in L(V) and m is a nonnegative integer s.t. null T^m = null T^(m+1), then null T^0 subset null T^1 subset ... subset null T^m = null T^(m+1) = null T^(m+2) = ...

//[T in L(V)] null T^(dimV) = null T^(dimV + 1) = ...
//[T in L(V), lambda eigenvalue of T]. {v | (T-lambda I)^j v = 0 for some j > 0} = null(T-lambda I)^(dim V)

nilpotent: N^j = 0 for some j > 0
  N in L(V) nilpotent => N^(dim V) = 0

[T in L(V), lambda in F]. foreach basis s.t. T has upper-tri matrix, lambda appears on diagonal dim(null((T - lambda I)^(dim V))) times.
  proof technique: WLOG only consider lambda = 0. induction on dimension. break down into cases lambda_n != 0, lambda_n = 0

multiplicity: = dim null(T-lambda*I)^dimV

V complex vector space. sum of multiplicities of all the eigenvalues of T equals V

characteristic polynomial: p(z) = (z-lambda_1)^d1 * ... * (z-lambda_m)^dm [V complex, T in L(V), lambda_1, ..., lambda_m distinct eigenvalues of T, dj = multiplicity of lambda_j].

Cayley-Hamilton Theorem: [V complex, T in L(V)]. q := characteristic polynomial of T. => q(T) = 0
  prove by induction on j: (T-l1I)...(T-ljI)vj = 0. Note that (T-ljI)vj in span(v1,...,vj-1)

[T in L(V). p in P(F)]. => null p(T) invariant under T

[V complex, T in L(V), lambda_1, ..., lambda_m distinct eigenvalues of T, U_1...U_m corresponding subspaces of generalized eigenvectors]
  V = U_1 oplus ... oplus U_m <=>
    each U_j is invariant under T <=>
    each (T - lambda_j I)|U_j is nilpotent

[V complex, T in L(V)] => exists basis of V consisting of generalized eigenvectors of T

Lemma: [N nilpotent operator on V] => exists basis of V with respect to which the matrix of N has all entries on and below diagonal 0's.

Theorem: [V complex, T in L(V), lambda_1, ..., lambda_m distinct eigenvalues of T] => exists basis of V w.r.t which T has a block diagonal matrix of the form Diagonal(A1, ..., Am) where each A_j is an upper triangular matrix, with lambda_j along the diagonal.

Jordan basis: if with respect to this basis T has a block diagonal matrix Diagonal(A_1, ..., A_m), where each A_j is an upper-triangular matrix with diagonal filled with some eigenvalue lambda_j of T, and the line directly above it filled with 1's, and all other 0's.

Lemma: If N in L(V) is nilpotent, then there exists vectors v1, ..., vk s.t.
  (a) (v1, Nv1, ..., N^(m(v1))v1, ..., vk, Nvk, ..., N^(m(vk))vk) is a basis of V
  (b) (N^(m(v1))v1, ..., N^(m(vk))vk) is a basis of null N
Theorem: [V complex, T in L(V)]. exists a basis of V that is a Jordan basis for T
